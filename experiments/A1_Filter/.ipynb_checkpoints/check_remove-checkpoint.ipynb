{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import ne_chunk, pos_tag\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.wsd import lesk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "wn_lem = WordNetLemmatizer() # wn_lem.lemmatize()\n",
    "\n",
    "\"\"\"\n",
    "    Input: (data, word_range, which_type)\n",
    "        data - one sentence\n",
    "        word_range - a nested list of clusters with their ranges (ie. [[[0,0],[0,19]],[[19,19],[59,59]]])\n",
    "        which_type - one of (\"name\", \"pro\", \"term\", \"all\"/nothing)\n",
    "        \n",
    "    return case: \n",
    "        1. if which_type == \"name\" and the function returns True >> THERE IS NAME LINK >> REMOVE\n",
    "        2. if which_type == \"pro\" and function returns True >> ALL LINKS ARE PRONOUN >> REMOVE\n",
    "        3. if which_type == \"term\" and function returns True >> THERE IS GENDER TERM LINK >> REMOVE\n",
    "        4. if which_type == \"all\" or not given and function returns True >> one of three remove cases hold >> REMOVE\n",
    "        5. if the function returns False >> NO NAME LINK and ALL LINKS ARE NOT PRONOUNS >> KEEP\n",
    "                   \n",
    "\"\"\"\n",
    "\n",
    "def check_remove(data, word_range, which_type=\"all\"):\n",
    "    gen_fam_term = [\"father\", \"mother\", \"son\", \"daughter\", \"husband\", \"wife\", \"brother\", \"sister\", \n",
    "                    \"grandfather\", \"grandmother\",\"grandson\", \"granddaughter\", \"uncle\", \"aunt\", \"nephew\", \"niece\"]\n",
    "    gen_term = [\"female\", \"male\", \"woman\", \"man\",\"girl\", \"boy\"]\n",
    "    pro_lst = [\"he\", \"she\", \"him\", \"her\", \"his\", \"hers\", \"himself\", \"herself\"]\n",
    "    \n",
    "    result = []\n",
    "    tok = word_tokenize(data)\n",
    "\n",
    "    for cluster in word_range:\n",
    "        #print(name_lst)\n",
    "        if (which_type == \"name\"): # check if the cluster has name link\n",
    "            # Check all the instances of human names in the sentence and build \"name_lst\"\n",
    "            name_lst = []\n",
    "            for sent_chunk in ne_chunk(pos_tag(word_tokenize(data))):\n",
    "                if hasattr(sent_chunk, 'label'):\n",
    "                    if (sent_chunk.label() == \"PERSON\"):\n",
    "                        name_lst.append(' '.join(c[0] for c in sent_chunk))\n",
    "                        #(print(\"TESTING\", c[0]) for c in sent_chunk)\n",
    "            result.append(any([((' '.join(w for w in tok[c[0]:c[1]+1])) in name_lst) \n",
    "                                for c in cluster]))\n",
    "            \n",
    "        elif (which_type == \"pro\"): # check if the cluster has only pronoun links\n",
    "            result.append(all([((c[0] == c[1]) and (tok[c[0]]).lower() in pro_lst) for c in cluster]))\n",
    "            \n",
    "            \n",
    "        elif (which_type == \"term\"): # check if the cluster has gendered term\n",
    "            for c in cluster:\n",
    "                for i in c:\n",
    "                    word_disam = lesk(tok, tok[i], 'n') # check definition assigned from word disambiguation\n",
    "                    #print(word_disam)\n",
    "                    # if the word is a valid English word check if it's person word and the definition contains gendered meaning\n",
    "                    if (word_disam is not None) and (word_disam.lexname() == \"noun.person\"): \n",
    "                        # now looking at all nouns in the range but after ACL we can use dependency parsing and only look at the head noun\n",
    "                        #print(word_disam.definition())\n",
    "                        result.append(any([wn_lem.lemmatize(w) in (gen_fam_term + gen_term + pro_lst)\n",
    "                                           and (x in (gen_fam_term + gen_term + pro_lst)\n",
    "                                           for x in wn._morphy(w, wordnet.NOUN)) # checks all possible morphological functions\n",
    "                                           for w in word_tokenize(word_disam.definition())]\n",
    "                                        + [tok[i] in (gen_fam_term + gen_term + pro_lst)]))\n",
    "                    else:\n",
    "                        result.append(False)\n",
    "                else:\n",
    "                    continue\n",
    "        else: # check all conditions at the same time\n",
    "            result.append(any([check_remove(data, word_range, which_type=\"name\"),\n",
    "                              check_remove(data, word_range, which_type=\"pro\"),\n",
    "                             check_remove(data, word_range, which_type=\"term\")]))\n",
    "            \n",
    "    return any(result)\n",
    "\n",
    "def filter_by_corpus(corpus,coref_ranges,prev_result,which_type=\"all\"):\n",
    "    this_result = []\n",
    "    for i in range(0,len(corpus)):\n",
    "        if prev_result[i] == 1:\n",
    "            print(corpus[i],coref_ranges[i])\n",
    "            if check_remove(corpus[i], coref_ranges[i], which_type):\n",
    "                this_result.append(0)\n",
    "            else:\n",
    "                this_result.append(1)\n",
    "        else:\n",
    "            this_result.append(0)\n",
    "    return this_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_A = \"Men more often than not connect through indicators of sexual access just as much as his do through sex.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = \"WASHINGTON-- In the wake of a string of abuses by New York police officers in the 1990s, she, Loretta E. Lynch, the top federal prosecutor in Brooklyn, spoke forcefully about the pain of a broken trust that African-Americans felt and said the responsibility for repairing generations of miscommunication and mistrust fell to law enforcement she.\"\n",
    "sent1 = \"SOME RANDOM SENT\"\n",
    "sent2 = 'Men went to his bank to deposit money.'\n",
    "test_sent = [sent,sent1,sent2,sent_A]\n",
    "ranges = [[[[0,0],[0,19]],[[19,19],[59,59]]],[],[[[0,0],[5,5]]],[[[0, 0], [15, 15]]]] # We want [f,0,t,t,]\n",
    "prev_result = [1,0,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_remove(sent_A, [[[0, 0], [15, 15]]], \"term\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_remove(sent, [[[0,0],[0,19]],[[19,19],[59,59]]], \"term\")\n",
    "\n",
    "#check_remove(sent, [[[21,s23],[19,19]],[[19,19],[59,59]]])\n",
    "check_remove(sent2, [[[0,0],[5,5]]], \"term\")\n",
    "#check_remove(sent2, [[[1,1],[4,4]]], \"pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WASHINGTON-- In the wake of a string of abuses by New York police officers in the 1990s, she, Loretta E. Lynch, the top federal prosecutor in Brooklyn, spoke forcefully about the pain of a broken trust that African-Americans felt and said the responsibility for repairing generations of miscommunication and mistrust fell to law enforcement she. [[[0, 0], [0, 19]], [[19, 19], [59, 59]]]\n",
      "Men went to his bank to deposit money. [[[0, 0], [5, 5]]]\n",
      "Men more often than not connect through indicators of sexual access just as much as his do through sex. [[[0, 0], [15, 15]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_by_corpus(test_sent,ranges,prev_result,\"term\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['men', 'man']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn._morphy(\"men\", wn.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a manservant who acts as a personal attendant to his employer'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet.synsets(\"landlord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'day'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn_lem.lemmatize(\"days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
