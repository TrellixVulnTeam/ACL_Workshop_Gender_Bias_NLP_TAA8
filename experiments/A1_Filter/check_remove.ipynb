{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import ne_chunk, pos_tag\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.wsd import lesk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wn_lem = WordNetLemmatizer() # wn_lem.lemmatize()\n",
    "\n",
    "\"\"\"\n",
    "    Input: (data, word_range, which_type)\n",
    "        data - one sentence\n",
    "        word_range - a nested list of clusters with their ranges (ie. [[[0,0],[0,19]],[[19,19],[59,59]]])\n",
    "        which_type - one of (\"name\", \"pro\", \"term\", \"all\"/nothing)\n",
    "        \n",
    "    return case: \n",
    "        1. if which_type == \"name\" and the function returns True >> THERE IS NAME LINK >> REMOVE\n",
    "        2. if which_type == \"pro\" and function returns True >> ALL LINKS ARE PRONOUN >> REMOVE\n",
    "        3. if which_type == \"term\" and function returns True >> THERE IS GENDER TERM LINK >> REMOVE\n",
    "        4. if which_type == \"all\" or not given and function returns True >> one of three remove cases hold >> REMOVE\n",
    "        5. if the function returns False >> NO NAME LINK and ALL LINKS ARE NOT PRONOUNS >> KEEP\n",
    "                   \n",
    "\"\"\"\n",
    "\n",
    "def check_remove(data, word_range, which_type=\"all\"):\n",
    "    gen_fam_term = [\"father\", \"mother\", \"son\", \"daughter\", \"husband\", \"wife\", \"brother\", \"sister\", \n",
    "                    \"grandfather\", \"grandmother\",\"grandson\", \"granddaughter\", \"uncle\", \"aunt\", \"nephew\", \"niece\"]\n",
    "    gen_term = [\"female\", \"male\", \"woman\", \"man\",\"girl\", \"boy\"]\n",
    "    pro_lst = [\"he\", \"she\", \"him\", \"her\", \"his\", \"hers\", \"himself\", \"herself\"]\n",
    "    \n",
    "    result = []\n",
    "    tok = word_tokenize(data)\n",
    "\n",
    "    for cluster in word_range:\n",
    "        #print(name_lst)\n",
    "        if (which_type == \"name\"): # check if the cluster has name link\n",
    "            # Check all the instances of human names in the sentence and build \"name_lst\"\n",
    "            name_lst = []\n",
    "            for sent_chunk in ne_chunk(pos_tag(word_tokenize(data))):\n",
    "                if hasattr(sent_chunk, 'label'):\n",
    "                    if (sent_chunk.label() == \"PERSON\"):\n",
    "                        name_lst.append(' '.join(c[0] for c in sent_chunk))\n",
    "                        (print(\"TESTING\", c[0]) for c in sent_chunk)\n",
    "            result.append(any([((' '.join(w for w in tok[c[0]:c[1]+1])) in name_lst) \n",
    "                                for c in cluster]))\n",
    "            \n",
    "        elif (which_type == \"pro\"): # check if the cluster has only pronoun links\n",
    "            result.append(all([((c[0] == c[1]) and (tok[c[0]]).lower() in pro_lst) for c in cluster]))\n",
    "            \n",
    "            \n",
    "        elif (which_type == \"term\"): # check if the cluster has gendered term\n",
    "            for c in cluster:\n",
    "                for i in c:\n",
    "                    word_disam = lesk(tok, tok[i], 'n') # check definition assigned from word disambiguation\n",
    "                    # if the word is a valid English word check if it's person word and the definition contains gendered meaning\n",
    "                    if (word_disam is not None) and (word_disam.lexname() == \"noun.person\"): \n",
    "                        # now looking at all nouns in the range but after ACL we can use dependency parsing and only look at the head noun\n",
    "                        result.append(any([wn_lem.lemmatize(w) in (gen_fam_term + gen_term) \n",
    "                                        for w in word_tokenize(word_disam.definition())]\n",
    "                                        + [tok[i] in (gen_fam_term + gen_term)]))\n",
    "                    else:\n",
    "                        result.append(False)\n",
    "                else:\n",
    "                    continue\n",
    "        else: # check all conditions at the same time\n",
    "            result.append(any([check_remove(data, word_range, which_type=\"name\"),\n",
    "                              check_remove(data, word_range, which_type=\"pro\"),\n",
    "                             check_remove(data, word_range, which_type=\"term\")]))\n",
    "            \n",
    "    return any(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = \"WASHINGTON-- In the wake of a string of abuses by New York police officers in the 1990s, she, Loretta E. Lynch, the top federal prosecutor in Brooklyn, spoke forcefully about the pain of a broken trust that African-Americans felt and said the responsibility for repairing generations of miscommunication and mistrust fell to law enforcement she.\"\n",
    "sent2 = 'My landlady went to his bank to deposit money.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check_remove(sent, [[[0,0],[0,19]],[[19,19],[59,59]]], \"all\")\n",
    "\n",
    "#check_remove(sent, [[[21,23],[19,19]],[[19,19],[59,59]]])\n",
    "#check_remove(sent2, [[[0,0],[4,4]]], \"term\")\n",
    "check_remove(sent2, [[[1,1]]], \"term\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
