{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import ne_chunk, pos_tag\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.wsd import lesk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "wn_lem = WordNetLemmatizer() # wn_lem.lemmatize()\n",
    "\n",
    "\"\"\"\n",
    "    Input: (data, word_range, which_type)\n",
    "        data - one sentence\n",
    "        word_range - a nested list of clusters with their ranges (ie. [[[0,0],[0,19]],[[19,19],[59,59]]])\n",
    "        which_type - one of (\"name\", \"pro\", \"term\", \"all\"/nothing)\n",
    "\n",
    "    return case: \n",
    "        1. if which_type == \"name\" and the function returns True >> THERE IS NAME LINK >> REMOVE\n",
    "        2. if which_type == \"pro\" and function returns True >> ALL LINKS ARE PRONOUN >> REMOVE\n",
    "        3. if which_type == \"term\" and function returns True >> THERE IS GENDER TERM LINK >> REMOVE\n",
    "        4. if which_type == \"all\" or not given and function returns True >> one of three remove cases hold >> REMOVE\n",
    "        5. if the function returns False >> NO NAME LINK and ALL LINKS ARE NOT PRONOUNS >> KEEP\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def check_remove(data, tok, word_range, which_type=\"all\"):\n",
    "    gen_fam_term = [\"father\", \"mother\", \"son\", \"daughter\", \"husband\", \"wife\", \"brother\", \"sister\",\n",
    "                    \"grandfather\", \"grandmother\", \"grandson\", \"granddaughter\", \"uncle\", \"aunt\", \"nephew\", \"niece\"]\n",
    "    gen_term = [\"female\", \"male\", \"woman\", \"man\", \"girl\", \"boy\"]\n",
    "    pro_lst = [\"he\", \"she\", \"him\", \"her\", \"his\", \"hers\", \"himself\", \"herself\"]\n",
    "\n",
    "    result = []\n",
    "    #tok = word_tokenize(data)\n",
    "    for cluster in word_range:\n",
    "        # print(name_lst)\n",
    "        #print(\"#### \",word_range)\n",
    "        if (which_type == \"name\"):  # check if the cluster has name link\n",
    "            #print(\"&&&&___NAME: \", data)\n",
    "            #print(\"&&&&___NAME_RANGE: \", cluster)\n",
    "\n",
    "            # Check all the instances of human names in the sentence and build \"name_lst\"\n",
    "            name_lst = []\n",
    "            for sent_chunk in ne_chunk(pos_tag(tok)):\n",
    "                if hasattr(sent_chunk, 'label'):\n",
    "                    if (sent_chunk.label() == \"PERSON\"):\n",
    "                        name_lst.append(' '.join(c[0] for c in sent_chunk))\n",
    "                        (print(\"TESTING\", c[0]) for c in sent_chunk)\n",
    "            result.append(any([((' '.join(w for w in tok[c[0]:c[1] + 1])) in name_lst)\n",
    "                               for c in cluster]))\n",
    "\n",
    "        elif (which_type == \"pro\"):  # check if the cluster has only pronoun links\n",
    "            #print(\"&&&&___PRO: \", data)\n",
    "            #print(\"&&&&___PRO_RANGE: \", cluster)\n",
    "            #print(tok)\n",
    "            #[print(c) for c in cluster]\n",
    "            result.append(all([((c[0] == c[1]) and (tok[c[0]]).lower() in pro_lst) for c in cluster]))\n",
    "\n",
    "\n",
    "        elif (which_type == \"term\"):  # check if the cluster has gendered term\n",
    "            #print(\"&&&&___TERM: \", data)\n",
    "            #print(\"&&&&___TERM_CLUSTER: \", cluster)\n",
    "\n",
    "            for c in cluster:\n",
    "                for i in c:\n",
    "                    word_disam = lesk(tok, tok[i], 'n')  # check definition assigned from word disambiguation\n",
    "                    # print(word_disam)\n",
    "                    # if the word is a valid English word check if it's person word and the definition contains gendered meaning\n",
    "                    if (word_disam is not None) and (word_disam.lexname() == \"noun.person\"):\n",
    "                        # now looking at all nouns in the range but after ACL we can use dependency parsing and only look at the head noun\n",
    "                        # print(word_disam.definition())\n",
    "                        result.append(any([wn_lem.lemmatize(w) in (gen_fam_term + gen_term + pro_lst)\n",
    "                                           and (x in (gen_fam_term + gen_term + pro_lst)\n",
    "                                                for x in wn._morphy(w, wn.NOUN))\n",
    "                                           # checks all possible morphological functions\n",
    "                                           for w in word_tokenize(word_disam.definition())]\n",
    "                                          + [tok[i] in (gen_fam_term + gen_term + pro_lst)]))\n",
    "                    else:\n",
    "                        result.append(False)\n",
    "                else:\n",
    "                    continue\n",
    "        else:  # check all conditions at the same time\n",
    "            result.append(any([check_remove(data, tok, word_range, which_type=\"name\"),\n",
    "                               check_remove(data, tok, word_range, which_type=\"pro\"),\n",
    "                               check_remove(data, tok, word_range, which_type=\"term\")]))\n",
    "\n",
    "    return any(result)\n",
    "\n",
    "\n",
    "def filter_by_corpus(corpus, tok_corpus, coref_ranges, prev_result, which_type=\"all\"):\n",
    "    this_result = []\n",
    "    for i in range(0, len(corpus)):\n",
    "        if prev_result[i] == 1:\n",
    "            # print(corpus[i],coref_ranges[i])\n",
    "            if check_remove(corpus[i],tok_corpus[i], coref_ranges[i], which_type):\n",
    "                this_result.append(0)\n",
    "            else:\n",
    "                this_result.append(1)\n",
    "        else:\n",
    "            this_result.append(0)\n",
    "    return this_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use case: \"name\" filter isn't working correctly (should be True when it returns False)\n",
    "sent1 = \"Paul Lukas plays the very earnest and decent head of his family.\"\n",
    "tok1 = ['Paul', 'Lukas', 'plays', 'the', 'very', 'earnest', 'and', 'decent', 'head', 'of', 'his', 'family', '.']\n",
    "range1 = [[[0, 1], [10, 10]]]\n",
    "check_remove(sent1, tok1, range1, \"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same use case as above (another example): \"name\" filter isn't working correctly (should be True when it returns False)\n",
    "sent1_1=\"All fines that have been given to us unjustly and against the law of the land, and all fines that we have exacted unjustly, shall be entirely remitted or the matter decided by a majority judgement of the twenty-five barons referred to below in the clause for securing the peace together with Stephen, archbishop of Canterbury, if he can be present, and such others as he wishes to bring with him.\"\n",
    "tok1_1=['All', 'fines', 'that', 'have', 'been', 'given', 'to', 'us', 'unjustly', 'and', 'against', 'the', 'law', 'of', 'the', 'land', ',', 'and', 'all', 'fines', 'that', 'we', 'have', 'exacted', 'unjustly', ',', 'shall', 'be', 'entirely', 'remitted', 'or', 'the', 'matter', 'decided', 'by', 'a', 'majority', 'judgement', 'of', 'the', 'twenty', '-', 'five', 'barons', 'referred', 'to', 'below', 'in', 'the', 'clause', 'for', 'securing', 'the', 'peace', 'together', 'with', 'Stephen', ',', 'archbishop', 'of', 'Canterbury', ',', 'if', 'he', 'can', 'be', 'present', ',', 'and', 'such', 'others', 'as', 'he', 'wishes', 'to', 'bring', 'with', 'him', '.']\n",
    "range1_1=[[[7, 7], [21, 21]], [[56, 60], [63, 63], [72, 72], [77, 77]]]\n",
    "check_remove(sent1_1, tok1_1, range1_1, \"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use case: 2 gender generalization clusters (highlight clusters in two different colors) \n",
    "sent2 = \"When the maker of a lost note pays the amount to the original owner, he should receive from him what is known as a bond of indemnity.\"\n",
    "tok2 = ['When', 'the', 'maker', 'of', 'a', 'lost', 'note', 'pays', 'the', 'amount', 'to', 'the', 'original', 'owner', ',', 'he', 'should', 'receive', 'from', 'him', 'what', 'is', 'known', 'as', 'a', 'bond', 'of', 'indemnity', '.']\n",
    "range2 = [[[1, 6], [15, 15]], [[11, 13], [19, 19]]]\n",
    "check_remove(sent2, tok2, range2, \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use case: one cluster is gender generalization and the other cluster is not\n",
    "sent3 = \"A nurse must take care of her patients and the boy likes to play with his toys.\"\n",
    "tok3 = ['A', 'nurse', 'must', 'take', 'care', 'of', 'her', 'patients', 'and', 'the', 'boy', 'likes', 'to', 'play', 'with', 'his', 'toys', '.']\n",
    "range3=[[[0, 1], [6, 6]], [[9, 10], [15, 15]]]\n",
    "check_remove(sent3, tok3, range3, \"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use case: a cluster contains \"the king\" and should be removed by \"term\" (returns False when should be True)\n",
    "sent4 = \"They sought him through all the ranks, and every time they met one of these officers they thought they had come face to face with the king.\"\n",
    "tok4 = ['They', 'sought', 'him', 'through', 'all', 'the', 'ranks', ',', 'and', 'every', 'time', 'they', 'met', 'one', 'of', 'these', 'officers', 'they', 'thought', 'they', 'had', 'come', 'face', 'to', 'face', 'with', 'the', 'king', '.']\n",
    "range4 = [[[0, 0], [11, 11], [17, 17], [19, 19]], [[2, 2], [26, 27]]]\n",
    "check_remove(sent4, tok4, range4, \"term\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same as above use case: a cluster contains \"the queen\" and should be removed by \"term\" (returns False when should be True)\n",
    "\n",
    "sent5 = \"This I have repeatedly witnessed in my observing hives, and admired the sagacity of the queen in economizing her necessary work after this fashion, instead of laboriously depositing the eggs in cells where they are not wanted.\"\n",
    "tok5 = ['This', 'I', 'have', 'repeatedly', 'witnessed', 'in', 'my', 'observing', 'hives', ',', 'and', 'admired', 'the', 'sagacity', 'of', 'the', 'queen', 'in', 'economizing', 'her', 'necessary', 'work', 'after', 'this', 'fashion', ',', 'instead', 'of', 'laboriously', 'depositing', 'the', 'eggs', 'in', 'cells', 'where', 'they', 'are', 'not', 'wanted', '.']\n",
    "range5 = [[[1, 1], [6, 6]], [[15, 16], [19, 19]]]\n",
    "check_remove(sent5, tok5, range5, \"term\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
